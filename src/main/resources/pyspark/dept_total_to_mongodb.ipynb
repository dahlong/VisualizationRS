{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========read csv data============ 2016-05-12 03:46:15.414388\n",
      "============group by dept_id / month data============\n",
      "============preparing list for mongodb============\n",
      "list size>> 1\n",
      "list size>> 2\n",
      "list size>> 3\n",
      "list size>> 4\n",
      "list size>> 5\n",
      "list size>> 6\n",
      "list size>> 7\n",
      "list size>> 8\n",
      "list size>> 9\n",
      "list size>> 10\n",
      "list size>> 11\n",
      "list size>> 12\n",
      "list size>> 13\n",
      "list size>> 14\n",
      "list size>> 15\n",
      "list size>> 16\n",
      "list size>> 17\n",
      "list size>> 18\n",
      "list size>> 19\n",
      "list size>> 20\n",
      "list size>> 21\n",
      "list size>> 22\n",
      "list size>> 23\n",
      "list size>> 24\n",
      "list size>> 25\n",
      "list size>> 26\n",
      "list size>> 27\n",
      "list size>> 28\n",
      "list size>> 29\n",
      "list size>> 30\n",
      "list size>> 31\n",
      "list size>> 32\n",
      "list size>> 33\n",
      "list size>> 34\n",
      "list size>> 35\n",
      "list size>> 36\n",
      "list size>> 37\n",
      "list size>> 38\n",
      "list size>> 39\n",
      "list size>> 40\n",
      "list size>> 41\n",
      "list size>> 42\n",
      "list size>> 43\n",
      "list size>> 44\n",
      "list size>> 45\n",
      "list size>> 46\n",
      "list size>> 47\n",
      "list size>> 48\n",
      "list size>> 49\n",
      "list size>> 50\n",
      "list size>> 51\n",
      "list size>> 52\n",
      "list size>> 53\n",
      "list size>> 54\n",
      "list size>> 55\n",
      "list size>> 56\n",
      "list size>> 57\n",
      "list size>> 58\n",
      "list size>> 59\n",
      "list size>> 60\n",
      "list size>> 61\n",
      "list size>> 62\n",
      "list size>> 63\n",
      "list size>> 64\n",
      "list size>> 65\n",
      "list size>> 66\n",
      "list size>> 67\n",
      "list size>> 68\n",
      "list size>> 69\n",
      "list size>> 70\n",
      "list size>> 71\n",
      "list size>> 72\n",
      "list size>> 73\n",
      "list size>> 74\n",
      "list size>> 75\n",
      "list size>> 76\n",
      "list size>> 77\n",
      "list size>> 78\n",
      "list size>> 79\n",
      "list size>> 80\n",
      "list size>> 81\n",
      "list size>> 82\n",
      "list size>> 83\n",
      "list size>> 84\n",
      "list size>> 85\n",
      "list size>> 86\n",
      "list size>> 87\n",
      "list size>> 88\n",
      "list size>> 89\n",
      "list size>> 90\n",
      "list size>> 91\n",
      "list size>> 92\n",
      "list size>> 93\n",
      "list size>> 94\n",
      "list size>> 95\n",
      "list size>> 96\n",
      "list size>> 97\n",
      "list size>> 98\n",
      "list size>> 99\n",
      "list size>> 100\n",
      "list size>> 101\n",
      "list size>> 102\n",
      "list size>> 103\n",
      "list size>> 104\n",
      "list size>> 105\n",
      "list size>> 106\n",
      "list size>> 107\n",
      "list size>> 108\n",
      "list size>> 109\n",
      "list size>> 110\n",
      "list size>> 111\n",
      "list size>> 112\n",
      "list size>> 113\n",
      "list size>> 114\n",
      "list size>> 115\n",
      "list size>> 116\n",
      "list size>> 117\n",
      "list size>> 118\n",
      "list size>> 119\n",
      "list size>> 120\n",
      "list size>> 121\n",
      "list size>> 122\n",
      "list size>> 123\n",
      "list size>> 124\n",
      "list size>> 125\n",
      "list size>> 126\n",
      "============start insert organzation statistics into mongodb============\n",
      "============finish to insert org total into mongodb============ 2016-05-12 03:49:52.193209\n"
     ]
    }
   ],
   "source": [
    "#dataframes department with total and month>> take around 3mins30sec\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pymongo import MongoClient\n",
    "from collections import OrderedDict\n",
    "from pyspark.sql.functions import *\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "client = MongoClient(\"mongodb://192.168.187.129:27017\")\n",
    "db = client.hrvisual\n",
    "\n",
    "conf = SparkConf().setAppName(\"building department_total_to_mongodb\")\n",
    "sc = SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#strYear='2015'\n",
    "strYear=sys.argv[1]\n",
    "\n",
    "collectionName = 'LEAVE_TYPE_%s' % strYear\n",
    "#if the collection exises in mongodb, then drop it\n",
    "#if collName in db.collection_names():\n",
    "#        db[collName].drop()            \n",
    "\n",
    "def getRddWithoutHeader(csvfname, fieldname):\n",
    "    f  = sc.textFile(csvfname)\n",
    "    r = f.filter(lambda l: fieldname in l)\n",
    "    r.collect()\n",
    "    r1 = f.subtract(r)\n",
    "    d=r1.map(lambda k: k.split(\",\"))\n",
    "    return d\n",
    "\n",
    "arrayferialname=[\"特別休假\",\"加班或假日出差轉補休\",\"生理假\",\"傷病假\",\"婚假\",\"家庭照顧假\", \\\n",
    "                    \"事假\",\"產檢假\",\"陪產假\",\"產假\",\"喪假\",\"國內公假\",\"國外公假\",\"公傷病假\", \"安胎假\"]\n",
    "\n",
    "def getFerialDict(fList, start):\n",
    "    mydic={}\n",
    "    for i in range(0,len(arrayferialname),1):\n",
    "        mydic[arrayferialname[i]]=int(fList[i+start])\n",
    "    \n",
    "    return mydic\n",
    "\n",
    "#build up schema\n",
    "structFields=[StructField(\"dept_id\", StringType()), StructField(\"dept_name\", StringType()), StructField(\"month\", IntegerType())]\n",
    "for i in range(1,len(arrayferialname) +1,1):\n",
    "    structFields.append(StructField(arrayferialname[i-1], IntegerType()))\n",
    "\n",
    "schema = StructType(structFields)\n",
    "\n",
    "print \"===========read csv data============\", datetime.datetime.now()\n",
    "data=getRddWithoutHeader('LEAVE_TYPE_%s.csv' % strYear,'dept_id')\n",
    "lines_temp = data.map(lambda p: (str(p[2]),unicode(p[3]),int(p[10]),int(p[11]),int(p[12]),int(p[13]),int(p[14]),int(p[15]), \\\n",
    "    int(p[16]), int(p[17]),int(p[18]),int(p[19]),int(p[20]),int(p[21]),int(p[22]),int(p[23]),int(p[24]),int(p[25])))\n",
    "\n",
    "\n",
    "lines_df = sqlContext.createDataFrame(lines_temp, schema)\n",
    "#print lines_df.printSchema()\n",
    "print \"============group by dept_id / month data============\"\n",
    "line_group=lines_df.groupBy(\"dept_id\", \"dept_name\").sum('特別休假','加班或假日出差轉補休','生理假','傷病假','婚假','家庭照顧假', \\\n",
    "            '事假','產檢假', '陪產假','產假','喪假','國內公假','國外公假','公傷病假', '安胎假')\n",
    "\n",
    "line_group_month=lines_df.groupBy(\"dept_id\", \"dept_name\", \"month\").sum('特別休假','加班或假日出差轉補休','生理假','傷病假','婚假', \\\n",
    "            '家庭照顧假', '事假','產檢假', '陪產假','產假','喪假','國內公假','國外公假','公傷病假', '安胎假')\n",
    "\n",
    "line_sort=line_group.sort(asc(\"dept_id\")).collect()\n",
    "print \"============preparing list for mongodb============\"\n",
    "mylist = []\n",
    "for a in line_sort: \n",
    "    rowDb={}\n",
    "    rowDb[\"dept_id\"]=a[0]\n",
    "    rowDb[\"dept_name\"]=a[1]\n",
    "    rowDb[\"Total\"]=getFerialDict(a,2)\n",
    "    line_filter=line_group_month.filter(line_group_month.dept_id==a[0]).collect()\n",
    "    for b in line_filter:\n",
    "        rowDb[str(b[2])]=getFerialDict(b,3)\n",
    "        \n",
    "    rowDb=OrderedDict(sorted(rowDb.items(), key=lambda t: t[0]))\n",
    "    mylist.append(rowDb)\n",
    "    print 'list size>>',len(mylist)   \n",
    "    \n",
    "print \"============start insert organzation statistics into mongodb============\"\n",
    "result=db[collectionName].insert_many(mylist)       \n",
    "print \"============finish to insert org total into mongodb============\", datetime.datetime.now()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish to insert into mongodb\n"
     ]
    }
   ],
   "source": [
    "#dataframes\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pymongo import MongoClient\n",
    "from collections import OrderedDict\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "client = MongoClient(\"mongodb://192.168.187.128:27017\")\n",
    "db = client.hrvisual\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "strYear='2015'\n",
    "\n",
    "collectionName = 'LEAVE_TYPE_%s' % strYear\n",
    "#if the collection exises in mongodb, then drop it\n",
    "#if collName in db.collection_names():\n",
    "#        db[collName].drop()            \n",
    "\n",
    "def getRddWithoutHeader(csvfname, fieldname):\n",
    "    f  = sc.textFile(csvfname)\n",
    "    r = f.filter(lambda l: fieldname in l)\n",
    "    r.collect()\n",
    "    r1 = f.subtract(r)\n",
    "    d=r1.map(lambda k: k.split(\",\"))\n",
    "    return d\n",
    "\n",
    "arrayferialname=[\"特別休假\",\"加班或假日出差轉補休\",\"生理假\",\"傷病假\",\"婚假\",\"家庭照顧假\", \\\n",
    "                    \"事假\",\"產檢假\",\"陪產假\",\"產假\",\"喪假\",\"國內公假\",\"國外公假\",\"公傷病假\", \"安胎假\"]\n",
    "\n",
    "#build up schema\n",
    "structFields=[StructField(\"dept_id\", StringType()), StructField(\"dept_name\", StringType())]\n",
    "for i in range(1,len(arrayferialname) +1,1):\n",
    "    structFields.append(StructField(arrayferialname[i-1], IntegerType()))\n",
    "\n",
    "schema = StructType(structFields)\n",
    "\n",
    "\n",
    "data=getRddWithoutHeader('LEAVE_TYPE_%s.csv' % strYear,'dept_id')\n",
    "lines_temp = data.map(lambda p: (str(p[2]),unicode(p[3]),int(p[11]),int(p[12]),int(p[13]),int(p[14]),int(p[15]),int(p[16]), \\\n",
    "    int(p[17]),int(p[18]),int(p[19]),int(p[20]),int(p[21]),int(p[22]),int(p[23]),int(p[24]),int(p[25])))\n",
    "\n",
    "\n",
    "lines_df = sqlContext.createDataFrame(lines_temp, schema)\n",
    "#print lines_df.printSchema()\n",
    "\n",
    "line_group=lines_df.groupBy(\"dept_id\", \"dept_name\").sum('特別休假','加班或假日出差轉補休','生理假','傷病假','婚假','家庭照顧假', \\\n",
    "            '事假','產檢假', '陪產假','產假','喪假','國內公假','國外公假','公傷病假', '安胎假')\n",
    "\n",
    "#insert into mongodb\n",
    "line_sort=line_group.sort(asc(\"dept_id\")).collect()\n",
    "for a in line_sort: \n",
    "    rowDb={}\n",
    "    rowDb[\"dept_id\"]=a[0]\n",
    "    rowDb[\"dept_name\"]=a[1]\n",
    "    \n",
    "    sumArray={}\n",
    "    for i in range(0,len(arrayferialname),1):\n",
    "        sumArray[arrayferialname[i]]=int(a[i+2])\n",
    "    \n",
    "    rowDb[\"Total\"]=sumArray\n",
    "    rowDb=OrderedDict(sorted(rowDb.items(), key=lambda t: t[0]))\n",
    "    #print 'rowDb=', rowDb\n",
    "    result=db[collectionName].insert_one(rowDb)\n",
    "    \n",
    "\n",
    "print \"finish to insert into mongodb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish to insert into mongodb\n"
     ]
    }
   ],
   "source": [
    "#dataframes\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql.types import *\n",
    "from pymongo import MongoClient\n",
    "from collections import OrderedDict\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "client = MongoClient(\"mongodb://192.168.187.128:27017\")\n",
    "db = client.hrvisual\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "strYear='2015'\n",
    "\n",
    "collectionName = 'TEST_%s' % strYear\n",
    "#if the collection exises in mongodb, then drop it\n",
    "if collectionName in db.collection_names():\n",
    "        db[collectionName].drop()            \n",
    "\n",
    "json={\n",
    "    \"org_id\" : \"91\",\n",
    "    \"org_name\" : \"財團法人國家實驗研究院國家災害防救科技中心\",\n",
    "    \"Total\" : {\n",
    "        \"公傷病假\" : 0,\n",
    "        \"產假\" : 0,\n",
    "        \"傷病假\" : 0,\n",
    "        \"安胎假\" : 0,\n",
    "        \"產檢假\" : 0,\n",
    "        \"加班或假日出差轉補休\" : 0,\n",
    "        \"婚假\" : 0,\n",
    "        \"國內公假\" : 0,\n",
    "        \"陪產假\" : 0,\n",
    "        \"特別休假\" : 0,\n",
    "        \"生理假\" : 0,\n",
    "        \"家庭照顧假\" : 0,\n",
    "        \"國外公假\" : 0,\n",
    "        \"事假\" : 0,\n",
    "        \"喪假\" : 0\n",
    "        }\n",
    "}\n",
    "result=db[collectionName].insert_one(json)\n",
    "    \n",
    "\n",
    "print \"finish to insert into mongodb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
